"""
Time Feature Extraction Module

Extracts cyclical time-based features from traffic data for ML models.
Uses sine/cosine encoding for hour to capture cyclical nature of time.

Task 3.1: Time Feature Extraction
"""

from pyspark.sql import DataFrame
from pyspark.sql.functions import (
    col, hour, dayofweek, month, when,
    sin, cos, radians, lit
)
import math


class TimeFeatureExtractor:
    """
    Extract cyclical time-based features from timestamp column.
    
    Features generated:
    - hour_sin, hour_cos: Cyclical encoding of hour (0-23)
    - day_of_week: 1=Monday, 7=Sunday
    - month: 1-12
    - is_weekend: Boolean (Saturday=6, Sunday=7)
    - is_rush_hour: Boolean (7-9 AM or 4-7 PM weekdays)
    
    Cyclical encoding ensures that hour 23 and hour 0 are treated as adjacent,
    which is critical for time series prediction accuracy.
    """
    
    def __init__(self, timestamp_col: str = "timestamp"):
        """
        Initialize the time feature extractor.
        
        Args:
            timestamp_col: Name of the timestamp column in the DataFrame
        """
        self.timestamp_col = timestamp_col
        
    def extract_features(self, df: DataFrame) -> DataFrame:
        """
        Extract time-based features from the DataFrame.
        
        Args:
            df: Spark DataFrame with timestamp column
            
        Returns:
            DataFrame with additional time feature columns
            
        Features:
        - hour_sin = sin(2π * hour / 24)
        - hour_cos = cos(2π * hour / 24)
        - day_of_week: 1=Monday through 7=Sunday
        - month: 1=January through 12=December
        - is_weekend: True if Saturday or Sunday
        - is_rush_hour: True if 7-9 AM or 4-7 PM on weekdays
        """
        # Extract hour from timestamp
        df = df.withColumn("hour_of_day", hour(col(self.timestamp_col)))
        
        # Cyclical encoding: hour_sin and hour_cos
        # This ensures smooth transitions (e.g., hour 23 → hour 0)
        df = df.withColumn(
            "hour_sin", 
            sin(radians(col("hour_of_day") * 360.0 / 24.0))
        )
        df = df.withColumn(
            "hour_cos",
            cos(radians(col("hour_of_day") * 360.0 / 24.0))
        )
        
        # Day of week (1=Monday, 7=Sunday in PySpark)
        df = df.withColumn("day_of_week", dayofweek(col(self.timestamp_col)))
        
        # Month (1-12)
        df = df.withColumn("month", month(col(self.timestamp_col)))
        
        # Is weekend (Saturday=7, Sunday=1 in Spark's dayofweek)
        # Note: Spark's dayofweek returns 1=Sunday, 2=Monday, ..., 7=Saturday
        df = df.withColumn(
            "is_weekend",
            when((col("day_of_week") == 1) | (col("day_of_week") == 7), 1).otherwise(0)
        )
        
        # Is rush hour (7-9 AM or 4-7 PM on weekdays)
        df = df.withColumn(
            "is_rush_hour",
            when(
                (col("is_weekend") == 0) & 
                (
                    ((col("hour_of_day") >= 7) & (col("hour_of_day") < 9)) |  # Morning rush
                    ((col("hour_of_day") >= 16) & (col("hour_of_day") < 19))   # Evening rush
                ),
                1
            ).otherwise(0)
        )
        
        # Drop intermediate hour_of_day column (we have hour_sin/hour_cos)
        df = df.drop("hour_of_day")
        
        return df
    
    def get_feature_names(self) -> list:
        """
        Get the list of feature names generated by this extractor.
        
        Returns:
            List of feature column names
        """
        return [
            "hour_sin",
            "hour_cos",
            "day_of_week",
            "month",
            "is_weekend",
            "is_rush_hour"
        ]


# Example usage
if __name__ == "__main__":
    from pyspark.sql import SparkSession
    from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType
    from datetime import datetime
    
    # Create Spark session
    spark = SparkSession.builder \
        .appName("TimeFeatureExtractorTest") \
        .getOrCreate()
    
    # Create sample data
    schema = StructType([
        StructField("sensor_id", StringType(), False),
        StructField("timestamp", TimestampType(), False),
        StructField("speed", DoubleType(), False)
    ])
    
    data = [
        ("LA_001", datetime(2025, 1, 6, 8, 0, 0), 45.5),   # Monday 8 AM (rush hour)
        ("LA_001", datetime(2025, 1, 6, 14, 30, 0), 62.3), # Monday 2:30 PM
        ("LA_001", datetime(2025, 1, 6, 17, 15, 0), 38.2), # Monday 5:15 PM (rush hour)
        ("LA_001", datetime(2025, 1, 11, 10, 0, 0), 55.8), # Saturday 10 AM (weekend)
    ]
    
    df = spark.createDataFrame(data, schema)
    
    # Extract features
    extractor = TimeFeatureExtractor()
    df_with_features = extractor.extract_features(df)
    
    # Show results
    print("\nTime Features Extracted:")
    df_with_features.select(
        "sensor_id", "timestamp", 
        "hour_sin", "hour_cos", 
        "day_of_week", "month",
        "is_weekend", "is_rush_hour"
    ).show(truncate=False)
    
    print("\nFeature Names:")
    print(extractor.get_feature_names())
    
    spark.stop()
