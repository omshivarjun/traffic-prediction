# ğŸ–¥ï¸ Complete UI Access Guide - All Your Data in One Place

## **ğŸ¯ QUICK ACCESS - All UIs at a Glance**

| Component | UI URL | What You'll See | Status |
|-----------|--------|-----------------|---------|
| **Kafka Messages** | http://localhost:8085 | Real-time data ingestion, topic messages | âœ… Active |
| **HDFS Data Storage** | http://localhost:9871 | File browser, data directories, ML models | âœ… Active |
| **Spark Processing** | http://localhost:8086 | Job monitoring, worker status, applications | âœ… Active |
| **YARN Resource Manager** | http://localhost:8089 | Hadoop job management, resource allocation | âœ… Active |
| **Spark Job History** | http://localhost:8189 | Completed job details, performance metrics | âœ… Active |
| **Traffic Dashboard** | http://localhost:3000/dashboard | Interactive heatmap, traffic visualization | âœ… Ready |

---

## **ğŸ” DETAILED UI BREAKDOWN**

### **1. ğŸ“¨ KAFKA UI - http://localhost:8085**
**Primary Use: Monitor real-time data ingestion**

#### **What You Can Access:**
- **Topics Tab**: All 8 Kafka topics including `traffic-events`
- **Messages Tab**: Live JSON messages from your CSV data
- **Consumers Tab**: Active data consumers
- **Brokers Tab**: Kafka cluster health
- **Connect Tab**: Data pipeline connectors

#### **Navigation Path:**
```
http://localhost:8085
â”œâ”€â”€ Topics â†’ traffic-events â†’ Messages (See your live data!)
â”œâ”€â”€ Consumers â†’ traffic-events-group (See who's reading)
â””â”€â”€ Brokers â†’ kafka-broker1 (Cluster health)
```

#### **What You'll See:**
```json
// Live traffic messages
{
  "timestamp": "2025-09-20 20:25:35",
  "sensor_id": "717462",
  "speed_mph": 65.5,
  "segment_id": "segment_001"
}
```

---

### **2. ğŸ—‚ï¸ HDFS NAMENODE UI - http://localhost:9871**
**Primary Use: Browse stored data files and ML models**

#### **What You Can Access:**
- **Overview**: Cluster storage capacity (Current: ~56MB+ used)
- **Datanodes**: Storage node health (1 active datanode)
- **Utilities â†’ Browse File System**: Your actual data directories
- **Startup Progress**: System initialization status

#### **Navigation Path:**
```
http://localhost:9871
â”œâ”€â”€ Utilities â†’ Browse the file system
â”œâ”€â”€ Navigate to: /traffic-data/
â”‚   â”œâ”€â”€ models/ (6 ML models - 56MB total)
â”‚   â”œâ”€â”€ raw/ (Original METR-LA data)
â”‚   â”œâ”€â”€ processed/ (Aggregated data)
â”‚   â””â”€â”€ predictions/ (ML outputs)
```

#### **What You'll See:**
- **File Browser**: Like Windows Explorer for big data
- **Model Files**: random_forest_speed.joblib (27.9MB)
- **Metadata**: model_metadata.json with performance metrics
- **Data Directories**: Organized by processing stage

---

### **3. âš¡ SPARK MASTER UI - http://localhost:8086**
**Primary Use: Monitor data processing jobs**

#### **What You Can Access:**
- **Workers**: 1 active worker node with resources
- **Running Applications**: Currently executing Spark jobs
- **Completed Applications**: Historical job performance
- **Application Detail**: Click any job for deep insights

#### **Navigation Path:**
```
http://localhost:8086
â”œâ”€â”€ Workers â†’ spark-worker (Resource usage)
â”œâ”€â”€ Running Applications â†’ [Job IDs] (Active processing)
â”œâ”€â”€ Completed Applications â†’ [History] (Past jobs)
â””â”€â”€ Application Detail â†’ Stages â†’ Tasks (Detailed execution)
```

#### **What You'll See:**
- **Cluster Resources**: CPU cores, memory allocation
- **Job Execution**: Stages, tasks, execution times
- **Performance Metrics**: Processing rates, data shuffle

---

### **4. ğŸ¯ YARN RESOURCE MANAGER - http://localhost:8089**
**Primary Use: Hadoop ecosystem job management**

#### **What You Can Access:**
- **Applications**: All submitted Hadoop/Spark jobs
- **Cluster Metrics**: Available memory, CPU cores
- **Nodes**: NodeManager status and resources
- **Scheduler**: Resource allocation queues

#### **Navigation Path:**
```
http://localhost:8089
â”œâ”€â”€ Applications â†’ All Applications (Job history)
â”œâ”€â”€ Cluster â†’ Nodes (Resource nodes)
â”œâ”€â”€ Cluster â†’ Scheduler (Resource queues)
â””â”€â”€ Tools â†’ Configuration (System settings)
```

---

### **5. ğŸ“Š SPARK HISTORY SERVER - http://localhost:8189**
**Primary Use: Detailed job execution analysis**

#### **What You Can Access:**
- **Completed Applications**: All finished Spark jobs
- **Job Performance**: Execution timelines, stages
- **SQL Queries**: If using Spark SQL
- **Environment**: Job configuration details

---

### **6. ğŸŒ TRAFFIC DASHBOARD - http://localhost:3000/dashboard**
**Primary Use: Interactive traffic visualization**

#### **What You Can Access:**
- **Interactive Map**: Los Angeles highway network
- **Traffic Heatmap**: Color-coded speed visualization
- **Sensor Markers**: 207 clickable traffic sensors
- **Real-time Updates**: Live data from Kafka stream

#### **Features:**
- **Red Zones**: Congested traffic (0-35 mph)
- **Yellow Zones**: Moderate traffic (35-55 mph)
- **Green Zones**: Free-flowing traffic (55+ mph)
- **Popup Details**: Sensor ID, speed, coordinates

---

## **ğŸš€ COMPLETE DATA ACCESS WORKFLOW**

### **Step 1: Check Data Ingestion**
1. Visit **Kafka UI**: http://localhost:8085
2. Go to **Topics** â†’ **traffic-events** â†’ **Messages**
3. Verify recent messages with timestamps

### **Step 2: Browse Stored Data**
1. Visit **HDFS UI**: http://localhost:9871
2. Click **Utilities** â†’ **Browse the file system**
3. Navigate to **/traffic-data/** directories
4. Explore **models/**, **processed/**, **raw/** folders

### **Step 3: Monitor Processing**
1. Visit **Spark UI**: http://localhost:8086
2. Check **Workers** (should show 1 active)
3. Look at **Applications** for job history

### **Step 4: View Resource Usage**
1. Visit **YARN UI**: http://localhost:8089
2. Check **Cluster** â†’ **Nodes** for resource health
3. Review **Applications** for job management

### **Step 5: Analyze Performance**
1. Visit **Spark History**: http://localhost:8189
2. Click on completed applications
3. Review execution details and performance

### **Step 6: See Final Visualization**
1. Visit **Dashboard**: http://localhost:3000/dashboard
2. Interact with traffic heatmap
3. Click sensors for live data

---

## **ğŸ¯ ONE-CLICK ACCESS SCRIPT**

Save this PowerShell script to open all UIs at once:

```powershell
# open-all-uis.ps1
Write-Host "Opening all METR-LA Pipeline UIs..." -ForegroundColor Green

Start-Process "http://localhost:8085"  # Kafka UI
Start-Process "http://localhost:9871"  # HDFS NameNode
Start-Process "http://localhost:8086"  # Spark Master
Start-Process "http://localhost:8089"  # YARN Resource Manager
Start-Process "http://localhost:8189"  # Spark History Server
Start-Process "http://localhost:3000/dashboard"  # Traffic Dashboard

Write-Host "All UIs opened in your default browser! ğŸš€" -ForegroundColor Yellow
```

---

## **ğŸ“± MOBILE-FRIENDLY ACCESS**

All UIs are accessible from any device on your network:
- Replace `localhost` with your computer's IP address (e.g., `192.168.1.100:8085`)
- Access from phones, tablets, or other computers on the same WiFi

---

## **ğŸ”§ TROUBLESHOOTING UI ACCESS**

### **If Any UI Doesn't Load:**
```powershell
# Check if the service is running
docker ps | findstr [service-name]

# Restart specific service if needed
docker restart [container-name]

# Check service logs
docker logs [container-name]
```

### **Common Issues:**
- **Port Conflicts**: Use the exact ports listed above
- **Service Starting**: Wait 2-3 minutes after `docker-compose up -d`
- **Browser Cache**: Try incognito/private browsing mode

---

## **ğŸŒŸ SUMMARY: Everything in Your Browser**

You have **6 powerful web interfaces** giving you complete visibility into:
- ğŸ“Š **Real-time data flow** (Kafka)
- ğŸ—„ï¸ **Stored data and models** (HDFS) 
- âš¡ **Processing jobs** (Spark)
- ğŸ¯ **Resource management** (YARN)
- ğŸ“ˆ **Performance analysis** (History Server)
- ğŸ—ºï¸ **Traffic visualization** (Dashboard)

**No command line needed - everything is accessible through your web browser! ğŸ¯**